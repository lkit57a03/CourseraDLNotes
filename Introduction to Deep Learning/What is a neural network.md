#Deep Learning
>It refers to build neural network with many hidden layers.

###A Simple Perceptron

I only takes a input and applies an activation Function to it. Just one neuron or a perceptron.

![A simple single perceptron](/Screenshots/Screenshot_1.png)

------------------------------

**This function that our perceptron represent is called a Relu function or a Rectifier Linear Unit Function**
![The function](../Screenshots/Screenshot_2.png)

**Suppose we have many features so we can extend this concept and add various input**
![Multi Layer Neural Network](../Screenshots/Screenshot_3.png)
>All the weights it figure out itself. We just give input and the output.

![A better representation](../Screenshots/Screenshot_4.png)